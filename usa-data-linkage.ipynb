{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sqlite3\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import re\n",
    "import seaborn as sns\n",
    "import time\n",
    "import requests\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start with Philadelphia, public housing, and all fire incidents 2021."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 14 minutes to run\n",
    "conn = sqlite3.Connection('./data/nfirs/fire_data.db')\n",
    "df = pd.read_sql(\"\"\"\n",
    "    select \n",
    "        INC_TYPE, \n",
    "        NUM_MILE,\n",
    "        STREET_PRE,\n",
    "        STREETNAME,\n",
    "        STREETTYPE,\n",
    "        STREETSUF,\n",
    "        APT_NO,\n",
    "        ia.STATE,\n",
    "        ia.CITY,\n",
    "        ia.ZIP5,\n",
    "        bi.PROP_LOSS,\n",
    "        bi.CONT_LOSS,\n",
    "        bi.OTH_DEATH,\n",
    "        bi.OTH_INJ,\n",
    "        bi.FF_DEATH,\n",
    "        bi.FF_INJ,\n",
    "        cast(substr(ia.INC_DATE, length(ia.INC_DATE) - 3, 4) AS integer) as inc_year\n",
    "    from basic_incident bi\n",
    "        join incident_address ia\n",
    "        using (INCIDENT_KEY)\n",
    "    where cast(substr(bi.INC_DATE, length(bi.INC_DATE) - 3, 4) AS integer) > 2014\n",
    "        and cast(substr(ia.INC_DATE, length(ia.INC_DATE) - 3, 4) AS integer) > 2014\n",
    "        and (bi.INC_TYPE = 111 or bi.INC_TYPE = 113 or bi.INC_TYPE = 114 or \n",
    "                 bi.INC_TYPE = 115 or bi.INC_TYPE = 116 or bi.INC_TYPE = 118)\n",
    "        \n",
    "\"\"\", conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns = [x.lower() for x in df.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 21 minutes to run\n",
    "df['address'] = df[['num_mile', 'street_pre', 'streetname', 'streettype', 'streetsuf', 'apt_no']] \\\n",
    "    .apply(lambda x: ' '.join(x.dropna().astype(str)), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "52"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.state.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "inc_type\n",
       "111    1905872\n",
       "113     808354\n",
       "118     269018\n",
       "114     107681\n",
       "116      48442\n",
       "115       6154\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby('inc_type').size().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "inc_year\n",
       "2018    465206\n",
       "2019    465096\n",
       "2016    461118\n",
       "2017    455779\n",
       "2015    453880\n",
       "2020    423229\n",
       "2021    421213\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby('inc_year').size().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.address = df.address.str.upper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jackv\\AppData\\Local\\Temp\\ipykernel_14888\\2237559633.py:1: DtypeWarning: Columns (104) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  public = pd.read_csv('./data/Public_Housing_Buildings.csv')\n"
     ]
    }
   ],
   "source": [
    "public = pd.read_csv('./data/Public_Housing_Buildings.csv')\n",
    "public.columns = [x.lower() for x in public.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "public['std_addr'] = public.std_addr.str.upper()\n",
    "public['std_st'] = public.std_st.str.upper()\n",
    "public['std_city'] = public.std_city.str.upper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For the 2015-2019 data\n",
    "fire_specific15 = df[(df['inc_type'].isin([111, 113])) & (df.inc_year.astype(int) < 2020)] \\\n",
    "    .groupby(['address', 'city', 'state', 'zip5']) \\\n",
    "    .size().reset_index()\n",
    "fire_specific15.columns = ['address', 'city', 'state', 'zip5', 'building_fires_11_19']\n",
    "fire_specific15 = fire_specific15.fillna(0) \n",
    "public = public.merge(fire_specific15, \n",
    "    left_on=['std_addr', 'std_city', 'std_st', 'std_zip5'], \n",
    "    right_on=['address', 'city', 'state', 'zip5'], how='left') \\\n",
    "    .drop(['address', 'city', 'state', 'zip5'], axis=1)\n",
    "public[['building_fires_11_19']] = public[['building_fires_11_19']].fillna(0).astype(int)\n",
    "\n",
    "# For the 2020-2021 validation data\n",
    "fire_specific20 = df[(df['inc_type'].isin([111, 113])) & (df.inc_year.astype(int) >= 2020)] \\\n",
    "    .groupby(['address', 'city', 'state', 'zip5']) \\\n",
    "    .size().reset_index()\n",
    "fire_specific20.columns = ['address', 'city', 'state', 'zip5', 'building_fires_20_21']\n",
    "fire_specific20 = fire_specific20.fillna(0) \n",
    "public = public.merge(fire_specific20, \n",
    "    left_on=['std_addr', 'std_city', 'std_st', 'std_zip5'], \n",
    "    right_on=['address', 'city', 'state', 'zip5'], how='left') \\\n",
    "    .drop(['address', 'city', 'state', 'zip5'], axis=1)\n",
    "public[['building_fires_20_21']] = public[['building_fires_20_21']].fillna(0).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4387"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(public[(public['building_fires_11_19'] > 0) | (public['building_fires_20_21'] > 0)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "171"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "public[((public['building_fires_11_19'] > 0) | (public['building_fires_20_21'] > 0)) & \n",
    "   (public.duplicated(subset=['std_addr', 'std_city', 'std_st', 'std_zip5'], keep=False))] \\\n",
    "   .std_addr.nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "171 of the identified street addresses are duplicates. In each case, we'll pick a random building and zero out the rest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_random_order = public.sample(frac=1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_random_order_no_fires = df_random_order[\n",
    "    (df_random_order['building_fires_11_19'] == 0) & \n",
    "    (df_random_order['building_fires_20_21'] == 0)\n",
    "]\n",
    "\n",
    "df_random_order_some_fires = df_random_order[\n",
    "    (df_random_order['building_fires_11_19'] > 0) | \n",
    "    (df_random_order['building_fires_20_21'] > 0)\n",
    "]\n",
    "\n",
    "is_duplicate = df_random_order_some_fires.duplicated(subset=[\n",
    "    'std_addr', \n",
    "    'std_city', \n",
    "    'std_st', \n",
    "    'std_zip5'\n",
    "], keep='first')\n",
    "\n",
    "df_random_order_some_fires.loc[is_duplicate, 'building_fires_11_19'] = 0\n",
    "df_random_order_some_fires.loc[is_duplicate, 'building_fires_20_21'] = 0\n",
    "\n",
    "public = pd.concat([df_random_order_some_fires, df_random_order_no_fires], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2896"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(public[(public['building_fires_11_19'] > 0) | (public['building_fires_20_21'] > 0)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "171"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "public[((public['building_fires_11_19'] > 0) | (public['building_fires_20_21'] > 0)) & \n",
    "   (public.duplicated(subset=['std_addr', 'std_city', 'std_st', 'std_zip5'], keep=False))] \\\n",
    "   .std_addr.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.replace(-4, np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "public.to_csv('fires_in_ph.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
